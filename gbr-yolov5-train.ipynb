{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tensorflow - Help Protect the Great Barrier Reef](https://www.kaggle.com/c/tensorflow-great-barrier-reef)\n",
    "> Detect crown-of-thorns starfish in underwater image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T10:40:24.652004Z",
     "iopub.status.busy": "2021-12-15T10:40:24.651659Z",
     "iopub.status.idle": "2021-12-15T10:44:53.877215Z",
     "shell.execute_reply": "2021-12-15T10:44:53.876329Z",
     "shell.execute_reply.started": "2021-12-15T10:40:24.65192Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install - q imagesize\n",
    "!pip install - qU wandb\n",
    "!add-apt-repository ppa: ubuntu-toolchain-r/test - y\n",
    "!apt-get update\n",
    "!apt-get upgrade libstdc++6 - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-15T10:44:53.879389Z",
     "iopub.status.busy": "2021-12-15T10:44:53.87911Z",
     "iopub.status.idle": "2021-12-15T10:44:57.683368Z",
     "shell.execute_reply": "2021-12-15T10:44:57.682647Z",
     "shell.execute_reply.started": "2021-12-15T10:44:53.879343Z"
    }
   },
   "outputs": [],
   "source": [
    "import imagesize\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "# import cupy as cp\n",
    "\n",
    "sys.path.append('../input/tensorflow-great-barrier-reef')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Points\n",
    "* One have to submit prediction using the provided **python time-series API**, which makes this competition different from previous Object Detection Competitions.\n",
    "* Each prediction row needs to include all bounding boxes for the image. Submission is format seems also **COCO** which means `[x_min, y_min, width, height]`\n",
    "* Copmetition metric `F2` tolerates some false positives(FP) in order to ensure very few starfish are missed. Which means tackling **false negatives(FN)** is more important than false positives(FP). \n",
    "$$F2 = 5 \\cdot \\frac{precision \\cdot recall}{4\\cdot precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Meta Data\n",
    "* `train_images/` - Folder containing training set photos of the form `video_{video_id}/{video_frame}.jpg`.\n",
    "\n",
    "* `[train/test].csv` - Metadata for the images. As with other test files, most of the test metadata data is only available to your notebook upon submission. Just the first few rows available for download.\n",
    "\n",
    "* `video_id` - ID number of the video the image was part of. The video ids are not meaningfully ordered.\n",
    "* `video_frame` - The frame number of the image within the video. Expect to see occasional gaps in the frame number from when the diver surfaced.\n",
    "* `sequence` - ID of a gap-free subset of a given video. The sequence ids are not meaningfully ordered.\n",
    "* `sequence_frame` - The frame number within a given sequence.\n",
    "* `image_id` - ID code for the image, in the format `{video_id}-{video_frame}`\n",
    "* `annotations` - The bounding boxes of any starfish detections in a string format that can be evaluated directly with Python. Does not use the same format as the predictions you will submit. Not available in test.csv. A bounding box is described by the pixel coordinate `(x_min, y_min)` of its lower left corner within the image together with its `width` and `height` in pixels --> (COCO format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:44:57.684936Z",
     "iopub.status.busy": "2021-12-15T10:44:57.684645Z",
     "iopub.status.idle": "2021-12-15T10:44:57.689542Z",
     "shell.execute_reply": "2021-12-15T10:44:57.68874Z",
     "shell.execute_reply.started": "2021-12-15T10:44:57.6849Z"
    }
   },
   "outputs": [],
   "source": [
    "FOLD = 6  # which fold to train\n",
    "REMOVE_NOBBOX = True  # remove images with no bbox\n",
    "ROOT_DIR = '/kaggle/input/tensorflow-great-barrier-reef/'\n",
    "IMAGE_DIR = '/kaggle/images'  # directory to save images\n",
    "LABEL_DIR = '/kaggle/labels'  # directory to save labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:44:57.692486Z",
     "iopub.status.busy": "2021-12-15T10:44:57.691983Z",
     "iopub.status.idle": "2021-12-15T10:44:59.195624Z",
     "shell.execute_reply": "2021-12-15T10:44:59.194708Z",
     "shell.execute_reply.started": "2021-12-15T10:44:57.692451Z"
    }
   },
   "outputs": [],
   "source": [
    "# create directories\n",
    "!mkdir - p {IMAGE_DIR}\n",
    "!mkdir - p {LABEL_DIR}\n",
    "\n",
    "\n",
    "def get_path(row):\n",
    "    row['old_image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n",
    "    row['image_path'] = f'{IMAGE_DIR}/video_{row.video_id}_{row.video_frame}.jpg'\n",
    "    row['label_path'] = f'{LABEL_DIR}/video_{row.video_id}_{row.video_frame}.txt'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:44:59.199118Z",
     "iopub.status.busy": "2021-12-15T10:44:59.198912Z",
     "iopub.status.idle": "2021-12-15T10:45:39.691658Z",
     "shell.execute_reply": "2021-12-15T10:45:39.690889Z",
     "shell.execute_reply.started": "2021-12-15T10:44:59.199093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n",
    "df = df.progress_apply(get_path, axis=1)\n",
    "df['annotations'] = df['annotations'].progress_apply(\n",
    "    lambda x: ast.literal_eval(x))\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:39.693266Z",
     "iopub.status.busy": "2021-12-15T10:45:39.69295Z",
     "iopub.status.idle": "2021-12-15T10:45:39.793429Z",
     "shell.execute_reply": "2021-12-15T10:45:39.792749Z",
     "shell.execute_reply.started": "2021-12-15T10:45:39.693229Z"
    }
   },
   "outputs": [],
   "source": [
    "df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\n",
    "data = (df.num_bbox > 0).value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:39.79508Z",
     "iopub.status.busy": "2021-12-15T10:45:39.794686Z",
     "iopub.status.idle": "2021-12-15T10:45:39.916674Z",
     "shell.execute_reply": "2021-12-15T10:45:39.915965Z",
     "shell.execute_reply.started": "2021-12-15T10:45:39.795043Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many image with starfish ?\n",
    "labels = ['Without Bounding Box', 'With Bounding Box']\n",
    "\n",
    "fig = go.Figure([go.Bar(x=labels,\n",
    "                        y=[data[0], data[1]], width=0.6)])\n",
    "fig.update_layout(title=\"Image with Starfish\", autosize=False,\n",
    "                  width=500, height=350, margin=dict(l=60, r=60, b=50, t=50, pad=4))\n",
    "fig.show()\n",
    "print(\n",
    "    f\"Without Bounding Box: {data[0]:0.2f}% | With Bounding Box: {data[1]:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:39.918289Z",
     "iopub.status.busy": "2021-12-15T10:45:39.918036Z",
     "iopub.status.idle": "2021-12-15T10:45:40.157718Z",
     "shell.execute_reply": "2021-12-15T10:45:40.157031Z",
     "shell.execute_reply.started": "2021-12-15T10:45:39.918254Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many image per video?\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(df['video_id'], color='#49A9DB').set_title(\n",
    "    'Nb of image per video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:40.159707Z",
     "iopub.status.busy": "2021-12-15T10:45:40.159244Z",
     "iopub.status.idle": "2021-12-15T10:45:41.026378Z",
     "shell.execute_reply": "2021-12-15T10:45:41.02569Z",
     "shell.execute_reply.started": "2021-12-15T10:45:40.159668Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many starfish detected per image ?\n",
    "fig = px.bar(df['num_bbox'].value_counts().drop(\n",
    "    0), title='Count of Bounding Boxes per image')\n",
    "fig.update_layout(autosize=False, width=700, height=400,\n",
    "                  margin=dict(l=60, r=60, b=50, t=50, pad=4))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filter\n",
    "* In this notebook, we use only **bboxed-images** (`~5k`). We can use all `~23K` images for train but most of them don't have any labels. So it would be easier to carry out experiments using only **bboxed images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:41.029738Z",
     "iopub.status.busy": "2021-12-15T10:45:41.029532Z",
     "iopub.status.idle": "2021-12-15T10:45:41.05248Z",
     "shell.execute_reply": "2021-12-15T10:45:41.051778Z",
     "shell.execute_reply.started": "2021-12-15T10:45:41.029713Z"
    }
   },
   "outputs": [],
   "source": [
    "if REMOVE_NOBBOX:\n",
    "    df = df.query(\"num_bbox>0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Images\n",
    "* We need to copy the Images to Current Directory(`/kaggle/working`) as `/kaggle/input` doesn't have **write access** which is needed for **YOLOv5**.\n",
    "* We can make this process faster using **Joblib** which uses **Parallel** computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:41.054116Z",
     "iopub.status.busy": "2021-12-15T10:45:41.053854Z",
     "iopub.status.idle": "2021-12-15T10:45:41.059096Z",
     "shell.execute_reply": "2021-12-15T10:45:41.058273Z",
     "shell.execute_reply.started": "2021-12-15T10:45:41.05408Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_copy(path):\n",
    "    data = path.split('/')\n",
    "    filename = data[-1]\n",
    "    video_id = data[-2]\n",
    "    new_path = os.path.join(IMAGE_DIR, f'{video_id}_{filename}')\n",
    "    shutil.copy(path, new_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:45:41.060993Z",
     "iopub.status.busy": "2021-12-15T10:45:41.060541Z",
     "iopub.status.idle": "2021-12-15T10:46:11.869126Z",
     "shell.execute_reply": "2021-12-15T10:46:11.868379Z",
     "shell.execute_reply.started": "2021-12-15T10:45:41.060952Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = df.old_image_path.tolist()\n",
    "_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(path)\n",
    "                                             for path in tqdm(image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:11.87095Z",
     "iopub.status.busy": "2021-12-15T10:46:11.870601Z",
     "iopub.status.idle": "2021-12-15T10:46:11.913295Z",
     "shell.execute_reply": "2021-12-15T10:46:11.912524Z",
     "shell.execute_reply.started": "2021-12-15T10:46:11.870912Z"
    }
   },
   "outputs": [],
   "source": [
    "def voc2yolo(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "\n",
    "    # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    bboxes = bboxes.copy().astype(float)\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]] / image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]] / image_height\n",
    "\n",
    "    w = bboxes[..., 2] - bboxes[..., 0]\n",
    "    h = bboxes[..., 3] - bboxes[..., 1]\n",
    "\n",
    "    bboxes[..., 0] = bboxes[..., 0] + w/2\n",
    "    bboxes[..., 1] = bboxes[..., 1] + h/2\n",
    "    bboxes[..., 2] = w\n",
    "    bboxes[..., 3] = h\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "\n",
    "    \"\"\"\n",
    "    bboxes = bboxes.copy().astype(\n",
    "        float)  # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]] * image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]] * image_height\n",
    "\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def coco2yolo(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    coco => [xmin, ymin, w, h]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "\n",
    "    # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    bboxes = bboxes.copy().astype(float)\n",
    "\n",
    "    # normolizinig\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]] / image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]] / image_height\n",
    "\n",
    "    # converstion (xmin, ymin) => (xmid, ymid)\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def yolo2coco(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    coco => [xmin, ymin, w, h]\n",
    "\n",
    "    \"\"\"\n",
    "    bboxes = bboxes.copy().astype(\n",
    "        float)  # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    # denormalizing\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]] * image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]] * image_height\n",
    "\n",
    "    # converstion (xmid, ymid) => (xmin, ymin)\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(\n",
    "        0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3,\n",
    "                    [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def draw_bboxes(img, bboxes, classes, class_ids, colors=None, show_classes=None, bbox_format='yolo', class_name=False, line_thickness=2):\n",
    "\n",
    "    image = img.copy()\n",
    "    show_classes = classes if show_classes is None else show_classes\n",
    "    colors = (0, 255, 0) if colors is None else colors\n",
    "\n",
    "    if bbox_format == 'yolo':\n",
    "\n",
    "        for idx in range(len(bboxes)):\n",
    "\n",
    "            bbox = bboxes[idx]\n",
    "            cls = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "\n",
    "            if cls in show_classes:\n",
    "\n",
    "                x1 = round(float(bbox[0])*image.shape[1])\n",
    "                y1 = round(float(bbox[1])*image.shape[0])\n",
    "                w = round(float(bbox[2])*image.shape[1]/2)  # w/2\n",
    "                h = round(float(bbox[3])*image.shape[0]/2)\n",
    "\n",
    "                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox,\n",
    "                             image,\n",
    "                             color=color,\n",
    "                             label=cls if class_name else str(get_label(cls)),\n",
    "                             line_thickness=line_thickness)\n",
    "\n",
    "    elif bbox_format == 'coco':\n",
    "\n",
    "        for idx in range(len(bboxes)):\n",
    "\n",
    "            bbox = bboxes[idx]\n",
    "            cls = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "\n",
    "            if cls in show_classes:\n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                w = int(round(bbox[2]))\n",
    "                h = int(round(bbox[3]))\n",
    "\n",
    "                voc_bbox = (x1, y1, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox,\n",
    "                             image,\n",
    "                             color=color,\n",
    "                             label=cls if class_name else str(cls_id),\n",
    "                             line_thickness=line_thickness)\n",
    "\n",
    "    elif bbox_format == 'voc_pascal':\n",
    "\n",
    "        for idx in range(len(bboxes)):\n",
    "\n",
    "            bbox = bboxes[idx]\n",
    "            cls = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "\n",
    "            if cls in show_classes:\n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                x2 = int(round(bbox[2]))\n",
    "                y2 = int(round(bbox[3]))\n",
    "                voc_bbox = (x1, y1, x2, y2)\n",
    "                plot_one_box(voc_bbox,\n",
    "                             image,\n",
    "                             color=color,\n",
    "                             label=cls if class_name else str(cls_id),\n",
    "                             line_thickness=line_thickness)\n",
    "    else:\n",
    "        raise ValueError('wrong bbox format')\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def get_imgsize(row):\n",
    "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "    return row\n",
    "\n",
    "\n",
    "np.random.seed(32)\n",
    "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "          for idx in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:11.916825Z",
     "iopub.status.busy": "2021-12-15T10:46:11.916563Z",
     "iopub.status.idle": "2021-12-15T10:46:11.928441Z",
     "shell.execute_reply": "2021-12-15T10:46:11.927025Z",
     "shell.execute_reply.started": "2021-12-15T10:46:11.91679Z"
    }
   },
   "outputs": [],
   "source": [
    "df.annotations[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:11.931156Z",
     "iopub.status.busy": "2021-12-15T10:46:11.930454Z",
     "iopub.status.idle": "2021-12-15T10:46:12.006495Z",
     "shell.execute_reply": "2021-12-15T10:46:12.005693Z",
     "shell.execute_reply.started": "2021-12-15T10:46:11.931119Z"
    }
   },
   "outputs": [],
   "source": [
    "df['bboxes'] = df.annotations.progress_apply(get_bbox)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Image-Size\n",
    "> All Images have same dimension, [Width, Height] =  `[1280, 720]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:12.008194Z",
     "iopub.status.busy": "2021-12-15T10:46:12.007878Z",
     "iopub.status.idle": "2021-12-15T10:46:18.243597Z",
     "shell.execute_reply": "2021-12-15T10:46:18.242808Z",
     "shell.execute_reply.started": "2021-12-15T10:46:12.008156Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.progress_apply(get_imgsize, axis=1)\n",
    "display(df.width.unique(), df.height.unique())\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏷️ Create Labels\n",
    "We need to export our labels to **YOLO** format, with one `*.txt` file per image (if no objects in image, no `*.txt` file is required). The *.txt file specifications are:\n",
    "\n",
    "* One row per object\n",
    "* Each row is class `[x_center, y_center, width, height]` format.\n",
    "* Box coordinates must be in **normalized** `xywh` format (from `0 - 1`). If your boxes are in pixels, divide `x_center` and `width` by `image width`, and `y_center` and `height` by `image height`.\n",
    "* Class numbers are **zero-indexed** (start from `0`).\n",
    "\n",
    "> Competition bbox format is **COCO** hence `[x_min, y_min, width, height]`. So, we need to convert form **COCO** to **YOLO** format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:18.24642Z",
     "iopub.status.busy": "2021-12-15T10:46:18.244758Z",
     "iopub.status.idle": "2021-12-15T10:46:21.510994Z",
     "shell.execute_reply": "2021-12-15T10:46:21.510278Z",
     "shell.execute_reply.started": "2021-12-15T10:46:18.246383Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "all_bboxes = []\n",
    "for row_idx in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[row_idx]\n",
    "    image_height = row.height\n",
    "    image_width = row.width\n",
    "    bboxes_coco = np.array(row.bboxes).astype(np.float32).copy()\n",
    "    num_bbox = len(bboxes_coco)\n",
    "    names = ['cots']*num_bbox\n",
    "    labels = [0]*num_bbox\n",
    "    # Create Annotation(YOLO)\n",
    "    with open(row.label_path, 'w') as f:\n",
    "        if num_bbox < 1:\n",
    "            annot = ''\n",
    "            f.write(annot)\n",
    "            cnt += 1\n",
    "            continue\n",
    "        bboxes_yolo = coco2yolo(image_height, image_width, bboxes_coco)\n",
    "        bboxes_yolo = np.clip(bboxes_yolo, 0, 1)\n",
    "        all_bboxes.extend(bboxes_yolo)\n",
    "        for bbox_idx in range(len(bboxes_yolo)):\n",
    "            annot = [str(labels[bbox_idx])] + list(bboxes_yolo[bbox_idx].astype(str)\n",
    "                                                   )+(['\\n'] if num_bbox != (bbox_idx+1) else [''])\n",
    "            annot = ' '.join(annot)\n",
    "            annot = annot.strip(' ')\n",
    "            f.write(annot)\n",
    "print('Missing:', cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌈 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:21.512924Z",
     "iopub.status.busy": "2021-12-15T10:46:21.512437Z",
     "iopub.status.idle": "2021-12-15T10:46:26.075547Z",
     "shell.execute_reply": "2021-12-15T10:46:26.074801Z",
     "shell.execute_reply.started": "2021-12-15T10:46:21.512885Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df[(df.num_bbox > 0)].sample(100)  # takes samples with bbox\n",
    "for idx in range(10):\n",
    "    row = df2.iloc[idx]\n",
    "    img = load_image(row.image_path)\n",
    "    image_height = row.height\n",
    "    image_width = row.width\n",
    "    bboxes_coco = np.array(row.bboxes)\n",
    "    bboxes_yolo = coco2yolo(image_height, image_width, bboxes_coco)\n",
    "    names = ['cots']*len(bboxes_coco)\n",
    "    labels = [0]*len(bboxes_coco)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(draw_bboxes(img=img,\n",
    "                           bboxes=bboxes_yolo,\n",
    "                           classes=names,\n",
    "                           class_ids=labels,\n",
    "                           class_name=True,\n",
    "                           colors=colors,\n",
    "                           bbox_format='yolo',\n",
    "                           line_thickness=2))\n",
    "    plt.axis('OFF')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📁 Create Folds and datasets\n",
    "> Number of samples aren't same in each fold which can create large variance in **Cross-Validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:26.076763Z",
     "iopub.status.busy": "2021-12-15T10:46:26.076539Z",
     "iopub.status.idle": "2021-12-15T10:46:27.130181Z",
     "shell.execute_reply": "2021-12-15T10:46:27.129494Z",
     "shell.execute_reply.started": "2021-12-15T10:46:26.076732Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "kf = GroupKFold(n_splits=10)  # num_folds=3 as there are total 3 videos\n",
    "df = df.reset_index(drop=True)\n",
    "df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df, y=df.video_id.tolist(), groups=df.sequence)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.fold.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:27.136569Z",
     "iopub.status.busy": "2021-12-15T10:46:27.134178Z",
     "iopub.status.idle": "2021-12-15T10:46:27.16455Z",
     "shell.execute_reply": "2021-12-15T10:46:27.1639Z",
     "shell.execute_reply.started": "2021-12-15T10:46:27.136526Z"
    }
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "train_df = df.query(\"fold!=@FOLD\")\n",
    "valid_df = df.query(\"fold==@FOLD\")\n",
    "train_files += list(train_df.image_path.unique())\n",
    "val_files += list(valid_df.image_path.unique())\n",
    "len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ Configuration\n",
    "The dataset config file requires\n",
    "1. The dataset root directory path and relative paths to `train / val / test` image directories (or *.txt files with image paths)\n",
    "2. The number of classes `nc` and \n",
    "3. A list of class `names`:`['cots']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:27.170378Z",
     "iopub.status.busy": "2021-12-15T10:46:27.168378Z",
     "iopub.status.idle": "2021-12-15T10:46:27.189406Z",
     "shell.execute_reply": "2021-12-15T10:46:27.188708Z",
     "shell.execute_reply.started": "2021-12-15T10:46:27.170339Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "cwd = '/kaggle/working/'\n",
    "\n",
    "with open(os.path.join(cwd, 'train.txt'), 'w') as f:\n",
    "    for path in train_df.image_path.tolist():\n",
    "        f.write(path+'\\n')\n",
    "\n",
    "with open(os.path.join(cwd, 'val.txt'), 'w') as f:\n",
    "    for path in valid_df.image_path.tolist():\n",
    "        f.write(path+'\\n')\n",
    "\n",
    "data = dict(\n",
    "    path='/kaggle/working',\n",
    "    train=os.path.join(cwd, 'train.txt'),\n",
    "    val=os.path.join(cwd, 'val.txt'),\n",
    "    nc=1,\n",
    "    names=['cots'],\n",
    ")\n",
    "\n",
    "with open(os.path.join(cwd, 'tgbr.yaml'), 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n",
    "f = open(os.path.join(cwd, 'tgbr.yaml'), 'r')\n",
    "print('\\nyaml:')\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [YOLOv5 Model](https://github.com/ultralytics/yolov5/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:46:27.195093Z",
     "iopub.status.busy": "2021-12-15T10:46:27.193207Z",
     "iopub.status.idle": "2021-12-15T10:46:40.729394Z",
     "shell.execute_reply": "2021-12-15T10:46:40.728554Z",
     "shell.execute_reply.started": "2021-12-15T10:46:27.195018Z"
    }
   },
   "outputs": [],
   "source": [
    "from yolov5 import utils\n",
    "%cd / kaggle/working\n",
    "!rm - r / kaggle/working/yolov5\n",
    "!git clone https: // github.com/ultralytics/yolov5  # clone\n",
    "!cp - r / kaggle/input/yolov5-lib-ds / kaggle/working/yolov5\n",
    "%cd yolov5\n",
    "%pip install - qr requirements.txt  # install\n",
    "\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T10:54:32.916162Z",
     "iopub.status.busy": "2021-12-15T10:54:32.915911Z",
     "iopub.status.idle": "2021-12-15T14:59:05.61073Z",
     "shell.execute_reply": "2021-12-15T14:59:05.609892Z",
     "shell.execute_reply.started": "2021-12-15T10:54:32.916134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 10 epochs\n",
    "!python train.py - -img 1280\\\n",
    "    - -batch 10\\\n",
    "    - -epochs 15\\\n",
    "    - -data / kaggle/working/tgbr.yaml\\\n",
    "    - -weights yolov5s.pt\\\n",
    "    - -workers 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:05.613033Z",
     "iopub.status.busy": "2021-12-15T14:59:05.612741Z",
     "iopub.status.idle": "2021-12-15T14:59:06.377732Z",
     "shell.execute_reply": "2021-12-15T14:59:06.376899Z",
     "shell.execute_reply.started": "2021-12-15T14:59:05.612997Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls runs/train/exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:06.381091Z",
     "iopub.status.busy": "2021-12-15T14:59:06.380849Z",
     "iopub.status.idle": "2021-12-15T14:59:07.165109Z",
     "shell.execute_reply": "2021-12-15T14:59:07.164411Z",
     "shell.execute_reply.started": "2021-12-15T14:59:06.381062Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread('runs/train/exp/labels_correlogram.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:07.167309Z",
     "iopub.status.busy": "2021-12-15T14:59:07.166934Z",
     "iopub.status.idle": "2021-12-15T14:59:07.717407Z",
     "shell.execute_reply": "2021-12-15T14:59:07.716688Z",
     "shell.execute_reply.started": "2021-12-15T14:59:07.167272Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread('runs/train/exp/labels.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔭 Batch Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:07.719038Z",
     "iopub.status.busy": "2021-12-15T14:59:07.718746Z",
     "iopub.status.idle": "2021-12-15T14:59:10.122472Z",
     "shell.execute_reply": "2021-12-15T14:59:10.121864Z",
     "shell.execute_reply.started": "2021-12-15T14:59:07.719001Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('runs/train/exp/train_batch0.jpg'))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('runs/train/exp/train_batch1.jpg'))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('runs/train/exp/train_batch2.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT Vs Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:10.124351Z",
     "iopub.status.busy": "2021-12-15T14:59:10.123866Z",
     "iopub.status.idle": "2021-12-15T14:59:12.267227Z",
     "shell.execute_reply": "2021-12-15T14:59:12.264917Z",
     "shell.execute_reply.started": "2021-12-15T14:59:10.124315Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(2*9, 3*5), constrained_layout=True)\n",
    "for row in range(3):\n",
    "    ax[row][0].imshow(plt.imread(f'runs/train/exp/val_batch{row}_labels.jpg'))\n",
    "    ax[row][0].set_xticks([])\n",
    "    ax[row][0].set_yticks([])\n",
    "    ax[row][0].set_title(\n",
    "        f'runs/train/exp/val_batch{row}_labels.jpg', fontsize=12)\n",
    "\n",
    "    ax[row][1].imshow(plt.imread(f'runs/train/exp/val_batch{row}_pred.jpg'))\n",
    "    ax[row][1].set_xticks([])\n",
    "    ax[row][1].set_yticks([])\n",
    "    ax[row][1].set_title(\n",
    "        f'runs/train/exp/val_batch{row}_pred.jpg', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:29.851576Z",
     "iopub.status.busy": "2021-12-15T14:59:29.851286Z",
     "iopub.status.idle": "2021-12-15T14:59:30.974321Z",
     "shell.execute_reply": "2021-12-15T14:59:30.973659Z",
     "shell.execute_reply.started": "2021-12-15T14:59:29.851547Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread('runs/train/exp/results.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:30.976406Z",
     "iopub.status.busy": "2021-12-15T14:59:30.97599Z",
     "iopub.status.idle": "2021-12-15T14:59:32.705284Z",
     "shell.execute_reply": "2021-12-15T14:59:32.704528Z",
     "shell.execute_reply.started": "2021-12-15T14:59:30.976373Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread('runs/train/exp/confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-15T14:59:32.707086Z",
     "iopub.status.busy": "2021-12-15T14:59:32.706746Z",
     "iopub.status.idle": "2021-12-15T14:59:35.515356Z",
     "shell.execute_reply": "2021-12-15T14:59:35.514664Z",
     "shell.execute_reply.started": "2021-12-15T14:59:32.707048Z"
    }
   },
   "outputs": [],
   "source": [
    "for metric in ['F1', 'PR', 'P', 'R']:\n",
    "    print(f'Metric: {metric}')\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(plt.imread(f'runs/train/exp/{metric}_curve.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
